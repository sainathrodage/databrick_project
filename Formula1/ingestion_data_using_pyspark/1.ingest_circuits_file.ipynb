{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a8e0d4b-189b-457f-84a2-08d6e00fafee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ingest circuits.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db85a924-7e7d-430f-b3df-16118c92ca17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 1 - Read the CSV file using the spark dataframe reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affd6d7e-6ab2-40f5-b8c9-14719644742b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/Configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db5d00dd-ccd2-47d6-87e3-618d93c7cdc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/common_functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c5753d2-6999-4f6d-a101-c41dcdd7b171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_data_source\",\"\")\n",
    "v_data_source=dbutils.widgets.get(\"p_data_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b10e4d23-3471-4964-a653-530508a92fa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251c0f05-0026-4795-9e81-7ddda91a80be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fcb1b85-0a5a-4d02-aef2-9b4e77883768",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_schema = StructType(fields=[StructField(\"circuitId\", IntegerType(), False),\n",
    "                                     StructField(\"circuitRef\", StringType(), True),\n",
    "                                     StructField(\"name\", StringType(), True),\n",
    "                                     StructField(\"location\", StringType(), True),\n",
    "                                     StructField(\"country\", StringType(), True),\n",
    "                                     StructField(\"lat\", DoubleType(), True),\n",
    "                                     StructField(\"lng\", DoubleType(), True),\n",
    "                                     StructField(\"alt\", IntegerType(), True),\n",
    "                                     StructField(\"url\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f5e48e-6eda-416e-bec9-583ecd393714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_df = spark.read \\\n",
    ".option(\"header\", True) \\\n",
    ".schema(circuits_schema) \\\n",
    ".csv(f\"{raw_folder_path}/circuits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "658c423a-9725-4ba9-bfaa-96108e2efe9e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 2 - Select only the required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2286ebb7-9d23-4e49-b481-fdfaf721ad2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18e2fa8-da45-45b6-826a-bddab0be32c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_selected_df = circuits_df.select(col(\"circuitId\"), col(\"circuitRef\"), col(\"name\"), col(\"location\"), col(\"country\"), col(\"lat\"), col(\"lng\"), col(\"alt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36ae8412-ae50-4c72-9183-0248d2af24e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 3 - Rename the columns as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cf1bf73-ccdc-417a-bb09-28d2e110c20f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b17e11c4-82f3-458c-be26-540aebfcc2d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_renamed_df = circuits_selected_df.withColumnRenamed(\"circuitId\", \"circuit_id\") \\\n",
    ".withColumnRenamed(\"circuitRef\", \"circuit_ref\") \\\n",
    ".withColumnRenamed(\"lat\", \"latitude\") \\\n",
    ".withColumnRenamed(\"lng\", \"longitude\") \\\n",
    ".withColumnRenamed(\"alt\", \"altitude\") \\\n",
    ".withColumn(\"data_source\",lit(v_data_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0ea1c5-85f6-42c2-bc22-b159e4ab5a62",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 4 - Add ingestion date to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b083479a-f952-4451-9e5d-3f95cdba8329",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_final_df = add_ingestion_date(circuits_renamed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f8fd832-7823-49da-bbf4-296da097e86e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 5 - Write data to datalake as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fb0d28-e743-4fe3-99c5-fb35eff49c15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "circuits_final_df.write.mode(\"overwrite\").parquet(f\"{processed_folder_path}/circuits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c9f688f-438f-4421-b56f-59a5698aef71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.read.parquet(\"/mnt/adlsproject/processed/formula1data/circuits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c00f4f21-8b93-4c06-bdc2-32a8d51ffa93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1.ingest_circuits_file",
   "widgets": {
    "p_data_source": {
     "currentValue": "testing",
     "nuid": "ffdda9c5-9fd5-4a58-a642-1fa80c7b2d1a",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "p_data_source",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
